{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math 425 Computation Linear Algebra\n",
    "\n",
    "\n",
    "### Module 2a\n",
    "#### Covering Orthogonality, least-squares, SVD and projection onto subspaces.\n",
    "#### Brent A. Thorne brentathorne@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment setup, try to make it clear which library I'm using for what\n",
    "import numpy as np  # nice arrays and other stuff\n",
    "import scipy as sci # like numpy but nicer\n",
    "import sympy as sym # symbollic maths \n",
    "from sympy.matrices import Matrix # pretty matrices\n",
    "from sympy import Eq # pretty equations\n",
    "from sympy.physics.quantum.dagger import Dagger # we'll want this later...\n",
    "from math import e, pi, sqrt # Mathy math math\n",
    "from mpl_toolkits.mplot3d import Axes3D # we like 3d quivers for tutorials\n",
    "import matplotlib.pyplot as plt # old standby for plotting like a villian\n",
    "from IPython.display import display, Math, Latex # used to display formatted results in the console\n",
    "sym.init_printing()  # initialize pretty printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Consider a subspace of $\\mathbb{R^n}$.  We define the $\\textit{orthogonal complement}$ $V^\\perp$ of $V$ as the set of those vectors $\\bf{w}$ in $\\mathbb{R^n}$ which are perpendicular to all vector in $V$, that is, the $\\textit{dot product}$ of any vector $\\bf{w}\\in V^\\perp$ with any vector $\\bf{v}\\in V$ is zero, i.e. $\\bf{w\\circ v} = 0$, for all $\\bf{v}\\in V$.\n",
    "\n",
    "Show that $V^\\perp$ is a subspace of $\\mathbb{R^n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obvoiusly $<0,v>=0$ for all $v\\in V$, thus $0\\in V^{\\perp}$. (i)\n",
    "\n",
    "Let $w_1,w_2 \\in V^{\\perp}$.\n",
    "\n",
    "Then, $<w_1+w_2,v> = <w_1,v> + <w_2,v> = 0+0 = 0$ for all $v\\in V$, thus $w_1+w_2\\in V^{\\perp}$. (ii)\n",
    "\n",
    "Given $w\\in V^{\\perp}$ and letting $c\\in\\mathbb{R}$.\n",
    "\n",
    "Then, $<cw,v> = c<w,v>=c(0) = 0$ for all $v\\in V$, thus $cw\\in V^{\\perp}$. (iii)\n",
    "\n",
    "Therefore by (i), (ii) and (iii), $V^{\\perp}$ is a subspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More mathematical gatekeeping... I see this sort of junk as pointless.\n",
    "\n",
    "Let's see why!\n",
    "\n",
    "Consider w as a orthogonal decompostion, and suppose $u,v\\in V$, with $v≠0$.\n",
    "\n",
    "Setting $c=\\frac{<u,v>}{\\|v\\|^2}$ and $w=u-\\frac{<u,v>}{\\|v\\|^2} v$.\n",
    "\n",
    "Thus by construction, $<w,v>=0$ and $u=cv+w$, and shows multiplictive and additive identity, the requires for a subspace.\n",
    "\n",
    "$\\square$ This construction a shows direct path to the Cauchy-Schwarz Inequality, which is more interesting than the original question...\n",
    "\n",
    "$\\|u\\|^2 = \\| \\frac{<u,v>}{\\|v\\|^2} \\|^2 + \\|w\\|^2$ * By Pythagoras\n",
    "\n",
    "$\\|u\\|^2 =\\frac{|<u,v>|^2}{\\|v\\|^2} + \\|w\\|^2$\n",
    "\n",
    "$\\|u\\|^2 \\ge\\frac{|<u,v>|^2}{\\|v\\|^2}$\n",
    "\n",
    "$\\|u\\|^2 \\|v\\|^2  \\ge\\frac{|<u,v>|^2}{\\|v\\|^2} \\|v\\|^2 $\n",
    "\n",
    "$\\|u\\|^2 \\|v\\|^2  \\ge{|<u,v>|^2} $\n",
    "\n",
    "$\\sqrt{\\|u\\|^2 \\|v\\|^2}  \\ge \\sqrt{|<u,v>|^2} $\n",
    "\n",
    "$\\|u\\|\\|v\\| \\ge |<u,v>| $\n",
    "\n",
    "$\\square$ Life has no meaning other than what you bring to it.  This freedom and responsibility now fuels my ever-growing Gödel existential angst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Let $A$ be a 3x3 matrix with eigenvalues $\\lambda_1=7, \\lambda_2=1, \\lambda_3=-1$ and corresponding eigenvectors $v_1 = \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}$, $v_2 = \\begin{bmatrix}-1\\\\1\\\\0\\end{bmatrix}$, $v_3 = \\begin{bmatrix}1\\\\1\\\\0\\end{bmatrix}$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Let $x=\\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$. Find $A^3x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}-7 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & -1\\end{matrix}\\right], \\  \\left[\\begin{matrix}-343 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & -1\\end{matrix}\\right], \\  \\left[\\begin{matrix}0 & -1 & 1\\\\0 & 1 & 1\\\\1 & 0 & 0\\end{matrix}\\right], \\  \\left[\\begin{matrix}1\\\\- \\frac{1}{2}\\\\\\frac{1}{2}\\end{matrix}\\right], \\  \\left[\\begin{matrix}0\\\\-1\\\\-343\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛⎡-7  0  0 ⎤  ⎡-343  0  0 ⎤  ⎡0  -1  1⎤  ⎡ 1  ⎤  ⎡ 0  ⎤⎞\n",
       "⎜⎢         ⎥  ⎢           ⎥  ⎢        ⎥  ⎢    ⎥  ⎢    ⎥⎟\n",
       "⎜⎢0   1  0 ⎥, ⎢ 0    1  0 ⎥, ⎢0  1   1⎥, ⎢-1/2⎥, ⎢ -1 ⎥⎟\n",
       "⎜⎢         ⎥  ⎢           ⎥  ⎢        ⎥  ⎢    ⎥  ⎢    ⎥⎟\n",
       "⎝⎣0   0  -1⎦  ⎣ 0    0  -1⎦  ⎣1  0   0⎦  ⎣1/2 ⎦  ⎣-343⎦⎠"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = sym.sqrt(-7)\n",
    "s2 = sym.sqrt(1)\n",
    "s3 = sym.sqrt(-1)\n",
    "\n",
    "v1 = Matrix([0,0,1])\n",
    "v2 = Matrix([-1,1,0])\n",
    "v3 = Matrix([1,1,0])\n",
    "x= Matrix([1,0,1])  \n",
    "\n",
    "#W = sym.diag(s1,s2,s3)\n",
    "W = sym.diag(-7,1,-1)\n",
    "\n",
    "#v1 = v1/v1.norm()\n",
    "#v2 = v2/v2.norm()\n",
    "#v3 = v3/v3.norm()\n",
    "\n",
    "P = Matrix([v1.T,v2.T,v3.T]).T\n",
    "C = P.inv()*x  # V.row_join(x).rref(pivots=False) # if we were asked to do this by hand... don't\n",
    "W,W**3,P,C, V*W**3*C  # think about this some more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\left[\\begin{matrix}x_{1}\\\\x_{2}\\\\x_{3}\\end{matrix}\\right]=c_{1} v_{1} + c_{2} v_{2} + c_{3} v_{3}$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show symbolic (as if this was hand written, remember as a man I'm better at symbols than numbers)\n",
    "# recall: x = c1*v1 + c2*v2 + c3*v3\n",
    "v = Matrix(sym.symbols('v1 v2 v3'))\n",
    "c = Matrix(sym.symbols('c1 c2 c3'))\n",
    "x = Matrix(sym.symbols('x1 x2 x3'))\n",
    "x, v.dot(c)\n",
    "display(Latex(f'${sym.latex(x)}={sym.latex(v.dot(c))}$'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Let $Q$ be the matrix whose columns are the normalized eigenvector (i.e. the unit eigenvector). Find $Q^T Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}0 & 0 & 1\\\\- \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0\\\\\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2} & 0\\end{matrix}\\right], \\  \\left[\\begin{matrix}0 & - \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2}\\\\0 & \\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2}\\\\1 & 0 & 0\\end{matrix}\\right], \\  \\left[\\begin{matrix}1 & 0 & 0\\\\0 & 1 & 0\\\\0 & 0 & 1\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛⎡ 0    0   1⎤  ⎡   -√2   √2⎤           ⎞\n",
       "⎜⎢           ⎥  ⎢0  ────  ──⎥           ⎟\n",
       "⎜⎢-√2   √2   ⎥  ⎢    2    2 ⎥  ⎡1  0  0⎤⎟\n",
       "⎜⎢────  ──  0⎥  ⎢           ⎥  ⎢       ⎥⎟\n",
       "⎜⎢ 2    2    ⎥, ⎢    √2   √2⎥, ⎢0  1  0⎥⎟\n",
       "⎜⎢           ⎥  ⎢0   ──   ──⎥  ⎢       ⎥⎟\n",
       "⎜⎢ √2   √2   ⎥  ⎢    2    2 ⎥  ⎣0  0  1⎦⎟\n",
       "⎜⎢ ──   ──  0⎥  ⎢           ⎥           ⎟\n",
       "⎝⎣ 2    2    ⎦  ⎣1   0    0 ⎦           ⎠"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is simply the indentity\n",
    "v1 = v1/v1.norm()\n",
    "v2 = v2/v2.norm()\n",
    "v3 = v3/v3.norm()\n",
    "Q = Matrix([v1.T,v2.T, v3.T]).T\n",
    "Q.T, Q, Q.T*Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For the data points (below) determine the best plane $z=a+bx+cy$ that best fits the data in the least-squares sense.\n",
    "\n",
    "|x|y|z|\n",
    "|-|-|-|\n",
    "|1|1|3|\n",
    "|1|2|6|\n",
    "|2|1|11|\n",
    "|2|2|-2|\n",
    "|3|2|0|\n",
    "|3|4|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}1 & 1 & 1\\\\1 & 1 & 2\\\\1 & 2 & 1\\\\1 & 2 & 2\\\\1 & 3 & 2\\\\1 & 3 & 4\\end{matrix}\\right], \\  \\left[\\begin{matrix}3\\\\6\\\\11\\\\-2\\\\0\\\\3\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛⎡1  1  1⎤  ⎡3 ⎤⎞\n",
       "⎜⎢       ⎥  ⎢  ⎥⎟\n",
       "⎜⎢1  1  2⎥  ⎢6 ⎥⎟\n",
       "⎜⎢       ⎥  ⎢  ⎥⎟\n",
       "⎜⎢1  2  1⎥  ⎢11⎥⎟\n",
       "⎜⎢       ⎥, ⎢  ⎥⎟\n",
       "⎜⎢1  2  2⎥  ⎢-2⎥⎟\n",
       "⎜⎢       ⎥  ⎢  ⎥⎟\n",
       "⎜⎢1  3  2⎥  ⎢0 ⎥⎟\n",
       "⎜⎢       ⎥  ⎢  ⎥⎟\n",
       "⎝⎣1  3  4⎦  ⎣3 ⎦⎠"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= Matrix([3,6,11,-2,0,3])\n",
    "X = Matrix([[1,1,1,1,1,1],[1,1,2,2,3,3],[1,2,1,2,2,4]]).T\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}21\\\\36\\\\34\\end{matrix}\\right], \\  \\left[\\begin{matrix}1 & 1 & 1 & 1 & 1 & 1\\\\1 & 1 & 2 & 2 & 3 & 3\\\\1 & 2 & 1 & 2 & 2 & 4\\end{matrix}\\right], \\  \\left[\\begin{matrix}3\\\\6\\\\11\\\\-2\\\\0\\\\3\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛                          ⎡3 ⎤⎞\n",
       "⎜                          ⎢  ⎥⎟\n",
       "⎜                          ⎢6 ⎥⎟\n",
       "⎜⎡21⎤  ⎡1  1  1  1  1  1⎤  ⎢  ⎥⎟\n",
       "⎜⎢  ⎥  ⎢                ⎥  ⎢11⎥⎟\n",
       "⎜⎢36⎥, ⎢1  1  2  2  3  3⎥, ⎢  ⎥⎟\n",
       "⎜⎢  ⎥  ⎢                ⎥  ⎢-2⎥⎟\n",
       "⎜⎣34⎦  ⎣1  2  1  2  2  4⎦  ⎢  ⎥⎟\n",
       "⎜                          ⎢0 ⎥⎟\n",
       "⎜                          ⎢  ⎥⎟\n",
       "⎝                          ⎣3 ⎦⎠"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_hat = X.T*y\n",
    "beta_hat, X.T, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Let $A=\\begin{bmatrix}2&1&0&-1\\\\0&-1&1&1 \\end{bmatrix}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. The 2-norm of a matrix $A$, $||A||_2$, also called the Euclidean matrix norm, is the largest singular value of $A$.  \n",
    "\n",
    "#### Find $||A||_2$ by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}2 & 1 & 0 & -1\\\\0 & -1 & 1 & 1\\end{matrix}\\right], \\  3, \\  2, \\  \\left[\\begin{matrix}2 & 1 & 0 & -1\\\\0 & -1 & 1 & 1\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛⎡2  1   0  -1⎤        ⎡2  1   0  -1⎤⎞\n",
       "⎜⎢            ⎥, 3, 2, ⎢            ⎥⎟\n",
       "⎝⎣0  -1  1  1 ⎦        ⎣0  -1  1  1 ⎦⎠"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's not good advice to do this by hand\n",
    "A= Matrix([[2,1,0,-1], [0,-1,1,1]])\n",
    "A, A.norm(), A.rank(), A.echelon_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}6 & -2\\\\-2 & 3\\end{matrix}\\right], \\  \\left\\{ 2 : 1, \\  7 : 1\\right\\}, \\  \\sqrt{7}\\right)$"
      ],
      "text/plain": [
       "⎛⎡6   -2⎤                  ⎞\n",
       "⎜⎢      ⎥, {2: 1, 7: 1}, √7⎟\n",
       "⎝⎣-2  3 ⎦                  ⎠"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the eigenvalue like a rational humanbeing would...\n",
    "# the largest is our Spectral Norm, note we use A*A.T due to short-fat nature of A\n",
    "A*A.T, (A*A.T).eigenvals(), sym.sqrt(max(list(((A*A.T).eigenvals()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Let $A=U\\Sigma V^T$ be the singular value decompostion of $A$. Find the matrix $U$ by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89442719,  0.4472136 ],\n",
       "       [ 0.4472136 ,  0.89442719]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again that is not good advice nor is it nice\n",
    "# let's find a quick solution first\n",
    "from scipy.linalg import svd\n",
    "a = np.array([[2, 1, 0, -1],\n",
    "       [0, -1, 1, 1]])\n",
    "u, s, vh = svd(a, full_matrices=False)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[ \\left( 2, \\  1, \\  \\left[ \\left[\\begin{matrix}\\frac{1}{2}\\\\1\\end{matrix}\\right]\\right]\\right), \\  \\left( 7, \\  1, \\  \\left[ \\left[\\begin{matrix}-2\\\\1\\end{matrix}\\right]\\right]\\right)\\right]$"
      ],
      "text/plain": [
       "⎡⎛      ⎡⎡1/2⎤⎤⎞  ⎛      ⎡⎡-2⎤⎤⎞⎤\n",
       "⎢⎜2, 1, ⎢⎢   ⎥⎥⎟, ⎜7, 1, ⎢⎢  ⎥⎥⎟⎥\n",
       "⎣⎝      ⎣⎣ 1 ⎦⎦⎠  ⎝      ⎣⎣1 ⎦⎦⎠⎦"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall short-fat nature of A, so work out U first\n",
    "(A*A.T).eigenvects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}- \\frac{2 \\sqrt{5}}{5} & \\frac{\\sqrt{5}}{5}\\\\\\frac{\\sqrt{5}}{5} & \\frac{2 \\sqrt{5}}{5}\\end{matrix}\\right], \\  \\left[\\begin{matrix}-0.89 & 0.45\\\\0.45 & 0.89\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛⎡-2⋅√5    √5 ⎤               ⎞\n",
       "⎜⎢──────   ── ⎥               ⎟\n",
       "⎜⎢  5      5  ⎥  ⎡-0.89  0.45⎤⎟\n",
       "⎜⎢            ⎥, ⎢           ⎥⎟\n",
       "⎜⎢  √5    2⋅√5⎥  ⎣0.45   0.89⎦⎟\n",
       "⎜⎢  ──    ────⎥               ⎟\n",
       "⎝⎣  5      5  ⎦               ⎠"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u2, u1 = [u[2][0] for u in (A*A.T).eigenvects()]\n",
    "u1 = u1/u1.norm()\n",
    "u2 = u2/u2.norm()\n",
    "U = Matrix([u1.T,u2.T]).T\n",
    "U, U.n(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Find the projection of $(1,1,1,1)$ onto $rowA$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}1\\\\1\\\\1\\\\1\\end{matrix}\\right], \\  \\left[\\begin{matrix}2 & 0\\\\1 & -1\\\\0 & 1\\\\-1 & 1\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛⎡1⎤  ⎡2   0 ⎤⎞\n",
       "⎜⎢ ⎥  ⎢      ⎥⎟\n",
       "⎜⎢1⎥  ⎢1   -1⎥⎟\n",
       "⎜⎢ ⎥, ⎢      ⎥⎟\n",
       "⎜⎢1⎥  ⎢0   1 ⎥⎟\n",
       "⎜⎢ ⎥  ⎢      ⎥⎟\n",
       "⎝⎣1⎦  ⎣-1  1 ⎦⎠"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = sym.ones(4,1)\n",
    "rowA =  Matrix(A.rowspace()).T # which is obviously A.T, as A is in echelon form\n",
    "b,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAA0AAAASCAYAAACAa1QyAAAA9UlEQVR4nJ3SvyvFYRTH8dfl/gcGs90fcWWyGMiIgVFSBqXUN5NNMjAY7j8gg4iFxKSUQZIMsrhJymTwc/g+6vTt271fPvV0Tuc579P5PD21LMv8VV0h78E0dnCHN7ziDFOxtx6gMWzgEcd4QC9GsIWh1PMdoVsMYw9fob6Ic4ymAdtxvSPsFgBoYTPljaKndnpP8aMqVMdEyg+qQivoxz4Oq0CzmMcNxn+L7aAZrOEaA3jpBM1hHVcJaMXLMmgBq7hMwFOxoQgtyY1fYBDPZWvEHzGJZXziVP4IRd2jGaG+FLvlnsp0gmZcL0Otw2mUeaqkf0E/uGsxD4TY4q4AAAAASUVORK5CYII=\n",
      "text/latex": [
       "$\\displaystyle 2$"
      ],
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = U*A\n",
    "V.col(0).dot(V.col(1))  # just checking myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}\\frac{4}{7}\\\\\\frac{5}{7}\\end{matrix}\\right], \\  \\left[\\begin{matrix}\\frac{8}{7}\\\\- \\frac{1}{7}\\\\\\frac{5}{7}\\\\\\frac{1}{7}\\end{matrix}\\right], \\  \\left[\\begin{matrix}1\\\\1\\\\1\\\\1\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛       ⎡8/7 ⎤  ⎡1⎤⎞\n",
       "⎜       ⎢    ⎥  ⎢ ⎥⎟\n",
       "⎜⎡4/7⎤  ⎢-1/7⎥  ⎢1⎥⎟\n",
       "⎜⎢   ⎥, ⎢    ⎥, ⎢ ⎥⎟\n",
       "⎜⎣5/7⎦  ⎢5/7 ⎥  ⎢1⎥⎟\n",
       "⎜       ⎢    ⎥  ⎢ ⎥⎟\n",
       "⎝       ⎣1/7 ⎦  ⎣1⎦⎠"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_hat = (A*A.T).inv()*A*b\n",
    "b_hat = A.T*x_hat\n",
    "x_hat, b_hat,  b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( \\left[\\begin{matrix}1.14285714285714\\\\-0.142857142857143\\\\0.714285714285714\\\\0.142857142857143\\end{matrix}\\right], \\  \\left[\\begin{matrix}1.14285714285714\\\\-0.142857142857143\\\\0.714285714285714\\\\0.142857142857143\\end{matrix}\\right]\\right)$"
      ],
      "text/plain": [
       "⎛⎡ 1.14285714285714 ⎤  ⎡ 1.14285714285714 ⎤⎞\n",
       "⎜⎢                  ⎥  ⎢                  ⎥⎟\n",
       "⎜⎢-0.142857142857143⎥  ⎢-0.142857142857143⎥⎟\n",
       "⎜⎢                  ⎥, ⎢                  ⎥⎟\n",
       "⎜⎢0.714285714285714 ⎥  ⎢0.714285714285714 ⎥⎟\n",
       "⎜⎢                  ⎥  ⎢                  ⎥⎟\n",
       "⎝⎣0.142857142857143 ⎦  ⎣0.142857142857143 ⎦⎠"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we already did the SVD so let's that to check again\n",
    "v = vh.transpose()\n",
    "v @ vh @ b, b_hat.n(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
